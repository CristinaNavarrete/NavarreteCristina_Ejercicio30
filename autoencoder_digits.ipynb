{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets\n",
    "import sklearn.preprocessing\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.models\n",
    "import torchvision.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "numeros = sklearn.datasets.load_digits()\n",
    "imagenes = numeros['images']  # Hay 1797 digitos representados en imagenes 8x8\n",
    "n_imagenes = len(imagenes)\n",
    "X = imagenes.copy()\n",
    "Y = numeros['target']\n",
    "print(np.shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1797, 1, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.autograd.Variable(torch.Tensor(X).float()).unsqueeze(1)\n",
    "print(inputs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# muestra algunos ejemplos\n",
    "\n",
    "n_items = inputs.data.size()[0]\n",
    "random_items = np.random.choice(np.arange(n_items), 5)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    item  = random_items[i]\n",
    "    plt.imshow(inputs[item][0].detach().numpy())\n",
    "    plt.title(Y[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1797, 1, 8, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normaliza\n",
    "mean = inputs.mean(dim=0)\n",
    "std = inputs.std(dim=0)\n",
    "std[std==0]=1.0\n",
    "\n",
    "for i in range(len(inputs)):\n",
    "    inputs[i] = (inputs[i])/std\n",
    "np.shape(inputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Los que se van a graficar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Número total de parámetros de la red convolucional\n",
    "N_Cs=[]\n",
    "#Dimensionalidad del espacio latente\n",
    "N_Ls=[]\n",
    "#losses\n",
    "losses=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primera corrida aumentando la dimensionalidad de los canales al final de ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define el autoencoder\n",
    "class Autoencoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder,self).__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3),\n",
    "            torch.nn.Conv2d(32,16,kernel_size=3),\n",
    "            torch.nn.Conv2d(16,10,kernel_size= 3))\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(10,8,kernel_size=3),\n",
    "            torch.nn.ConvTranspose2d(8,16,kernel_size=3),\n",
    "            torch.nn.ConvTranspose2d(16,1,kernel_size=3))\n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializa modelo, loss y optimizador\n",
    "num_epochs = 100\n",
    "model = Autoencoder()\n",
    "distance = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1E-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:2.7593\n",
      "epoch [26/100], loss:0.7089\n",
      "epoch [51/100], loss:0.5165\n",
      "epoch [76/100], loss:0.4272\n",
      "epoch [100/100], loss:0.3815\n"
     ]
    }
   ],
   "source": [
    "# entrenamiento\n",
    "loss_list = [] \n",
    "for epoch in range(num_epochs):\n",
    "    output = model(inputs)\n",
    "    loss = distance(output, inputs)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_list.append(loss.item())\n",
    "    if epoch==0 or epoch==25 or epoch==50 or epoch==75 or epoch==99:\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1797, 10, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "x_transform = model(inputs)\n",
    "latent_space = model.encoder(inputs)\n",
    "print(latent_space.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAz8AAAHtCAYAAAA3PMBOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de5jdZXnu8fuZNTOZnEPIgZiEJEAA4xGYTYG0yAatiBRsiy22VbG6o6Wg9mSxB9ut7VXb7suq1eJOEdDClrZoa0ppqXLQUgwQIAhJCIQIJjGQcMo5mdOz/5gVOokTMrOeNb/3nbzfz3XlYmbNetd7z3DPb80za81vmbsLAAAAAI50LakDAAAAAEAVGH4AAAAAFIHhBwAAAEARGH4AAAAAFIHhBwAAAEARGH4AAAAAFIHhBwAAAEARGH4yZ2YLzWyvmd2QOgvKY2ZTzeyfzGyXmT1tZr+UOhPKYmZ31Y+BO+v/1qbOhPKY2Q1mttnMtpvZ42b2gdSZUCYzu9TM1tTvl580s59KnWm0aU0dAIf1RUn3pw6BYn1RUpekmZLeKOlfzexhd1+VNhYKc4W7X5M6BIr2Z5Le7+77zOxkSXeZ2UPu/kDqYCiHmb1F0p9L+kVJ90malTbR6MQjPxkzs0slvSTp9tRZUB4zGy/p5yX9obvvdPe7JS2T9O60yQCgWu6+yt337X+3/u/4hJFQpv8t6ZPuvtzd+9x9k7tvSh1qtGH4yZSZTZL0SUm/mToLinWipB53f3zAZQ9Lek2iPCjXn5nZc2b2X2Z2TuowKJOZ/Y2Z7Zb0mKTNkm5NHAkFMbOapE5J081snZltNLMvmNnY1NlGG4affH1K0pfdfWPqICjWBEnbD7psm6SJCbKgXL8r6ThJsyUtlfQvZsZv3FE5d79c/ce/n5L0DUn7XnkF0FQzJbVJukT9HXyjpFMk/UHKUKMRw0+GzOyNkt4s6a9SZ0HRdkqadNBlkyTtSJAFhXL3e919h7vvc/evSPovSRekzoUyuXtv/SnAcyT9Wuo8KMqe+n//2t03u/tzkj4jjofDxgkP8nSOpPmSfmhmUv9v4GtmtsjdT02YC2V5XFKrmS109yfql71BEic7QEouyVKHQPFaxd/8oELu/qKZbVT/MfDli1PlGc145CdPS9V/UH1j/d+XJP2rpLemDIWyuPsu9T+145NmNt7MFku6WNLfpU2GUpjZFDN7q5l1mFmrmf2ypLMl/XvqbCiHmc2on154gpnVzOytkt4lTkaE6l0n6cp6J4+S9BuSbkmcadThkZ8MuftuSbv3v29mOyXtdfet6VKhUJdLulbSFknPS/o1TnONCrVJ+hNJJ0vqVf8fmr/joJNwACPN1f8Uty+p/5fGT0v6qLsvS5oKJfqUpGnqf2bGXkn/IOlPkyYahcydR8wAAAAAHPl42hsAAACAIjD8AAAAACgCww8AAACAIjD8AAAAACgCww8AAACAImR7qut2G+MdGp86Rsy4jvBNHHfCc6H1678/IZwhBzv04nPuPr3qfXPoobXWQuv9uPjvOHqfaw+tr72wK5whtb3apS7fl+TFNXPoYe/CMaH1rx77YjiDB1/Pb/UzM8IZ2rak7XKqHkY7eOLrdx/+Sofx6M6jQ+uPGbstnMGDr6/7zEtTwhnat8e+D2xH/P9FyffJUV2z4/mPnrwjtH7H0034Gu7aE7+NgMixMNvhp0Pj9RN2XuoYIbboNeHbuOGfl4bW//LcxeEMOfi23/x0in1z6GFtytTQ+t4vjQtn2HbtnND6yTcuD2dI7V5P93qGOfRw+1/HXsz+e2/4ejhDt/eG1nf+5ZXhDMd89p7wbUSk6mG0g7fdtjKc4dX/9e7Q+t993W3hDF0e+7HpL5ddHM5w7H90hda33v5AOEPJ98lRP7jyzPBtvOftd4bWf/dDPxHOYPc8HL6NiMixkKe9AQAAACgCww8AAACAIlQ6/JjZ+Wa21szWmdlVVe4NSHQQeaCHyAE9RGp0EClUNvyYWU3SFyW9TdIiSe8ys0VV7Q/QQeSAHiIH9BCp0UGkUuUjP6dLWufu6929S9JNkuJ/+QcMHR1EDughckAPkRodRBJVDj+zJW0Y8P7G+mVAVeggckAPkQN6iNToIJLI6lTXZrZE0hJJ6lD89LxAI+ghckAPkRodRA7oIZqtykd+NkmaO+D9OfXLXubuS92909072xR7QT1gEIftoEQPMeLoIXLAfTJS41iIJKocfu6XtNDMFphZu6RLJS2rcH+ADiIH9BA5oIdIjQ4iicqe9ubuPWZ2haTbJNUkXevuq6raH6CDyAE9RA7oIVKjg0il0r/5cfdbJd1a5Z7AQHQQOaCHyAE9RGp0EClU+iKnAAAAAJAKww8AAACAImR1qusjzeY/7AvfxrTa+CYkwWj29JKTQ+tXvfpvwhku+dCbQ+t3P3RiOEPv6sfDt1GqPe84PXwbZ81YEVr/DzsnhzN84mu/HFo/67HucAY05tzLPhC+jcnTYz+yXH9d/PUzn7lsb+wG5u4JZ9j6htjpnmfdHo5QtOfff2Zo/ePvvTqc4Y2fvjy0fuY994QzjGY88gMAAACgCAw/AAAAAIrA8AMAAACgCAw/AAAAAIrA8AMAAACgCAw/AAAAAIrA8AMAAACgCAw/AAAAAIrA8AMAAACgCAw/AAAAAIrA8AMAAACgCAw/AAAAAIrA8AMAAACgCAw/AAAAAIrA8AMAAACgCAw/AAAAAIrQmjpAznZcekZo/ade89Vwhp+88oOh9ZNO2BLO0LvuB+HbKFXLG14dvo1XvXlDaP3Cuy4LZ6g9MS60vuvy3nCGhVeEb6JY4zbsCt/G1q4JofXXvfOCcIZ5D98Tvg2k0fYfK8K3MTm4/oX3nRnOsG9bR2j9CV/pDmdouZvvg5R2/HTseLro6svDGeZ+ng5E8MgPAAAAgCIw/AAAAAAoAsMPAAAAgCIw/AAAAAAoQmXDj5nNNbM7zWy1ma0ys49UtTcg0UHkgR4iB/QQqdFBpFLl2d56JP2Wuz9oZhMlPWBm33L31RVmQNnoIHJAD5EDeojU6CCSqOyRH3ff7O4P1t/eIWmNpNlV7Q/QQeSAHiIH9BCp0UGkkuRvfsxsvqRTJN2bYn+ADiIH9BA5oIdIjQ6iSpW/yKmZTZD0dUkfdfftB31siaQlktSh2IsqAofySh2sf5weYsTRQ+SA+2SkxrEQVav0kR8za1N/wW90928c/HF3X+rune7e2aYxVUZDIQ7XQYkeYuTRQ+SA+2SkxrEQKVR5tjeT9GVJa9z9M1XtC+xHB5EDeogc0EOkRgeRSpWP/CyW9G5J55rZyvq/CyrcH6CDyAE9RA7oIVKjg0iisr/5cfe7JVlV+wEHo4PIAT1EDughUqODSCXJ2d4AAAAAoGoMPwAAAACKUPmprkeTU3/rodD6P17zM+EMx9z1RGj9Zd97IJzh03/1S6H106/+XjjDaOXt8W+xLTsmhNa3rY6fGnTun9wTWv/kjaeEM+z8hTNC6yf8w/JwhtHKH1gVvo0f7pgfWr/hdzrCGcatPCu0/lX/J9ZjjG7bFsZvY+Z3aqH1LXffHw+BhrXOib+GaseY7tD6SY/2hjMghkd+AAAAABSB4QcAAABAERh+AAAAABSB4QcAAABAERh+AAAAABSB4QcAAABAERh+AAAAABSB4QcAAABAERh+AAAAABSB4QcAAABAERh+AAAAABSB4QcAAABAERh+AAAAABSB4QcAAABAERh+AAAAABSB4QcAAABAEVpTBxgpz374rPBtnNV+V2j9Mb/ZFc7wxO+eFLyFB8IZjr10fWj9nqvDEUatbQvHh2+jp3dHaP3cP7knnCGq77kx4dtwflWT1JbvvCq0ftZPPRPOMPVnNofWb37hzHiGa78Xvg2kMfP+vvBtbOmMHYgmhxMgYs+iWeHb6OndE1r/0nti9+mS9Pyi2M+4c/80/c8FKfHjBAAAAIAiMPwAAAAAKALDDwAAAIAiMPwAAAAAKELlw4+Z1czsITO7peq9AYkOIg/0EDmgh0iNDqJqKR75+YikNQn2Bfajg8gBPUQO6CFSo4OoVKXDj5nNkfR2SddUuS+wHx1EDughckAPkRodRApVP/LzWUkfkzToyfbNbImZrTCzFd3aV20ylOIVOyjRQ1SCHiIH3CcjNY6FqFxlw4+ZXShpi7sf8lU33X2pu3e6e2eb4i+KCAw0lA5K9BAjix4iB9wnIzWOhUilykd+Fku6yMyeknSTpHPN7IYK9wfoIHJAD5EDeojU6CCSqGz4cfePu/scd58v6VJJd7j7r1S1P0AHkQN6iBzQQ6RGB5EKr/MDAAAAoAitKTZ197sk3ZVib0Cig8gDPUQO6CFSo4OoEo/8AAAAACgCww8AAACAIiR52lsVZn7+nvBt/N3cN4XWz/vSpnCG9824I7T+6NrOcIZn/nZBaP1kPRvOMFp1TbDwbXR310LrayedEM7Qu3ZdLMPe+NfhmfO7Qusn3hSOULS5fxo7ptYmTQpnWPfh14bW9/x0/Hg49drwTSCRCT/YEb6N514/pQlJkErb9tj9iBS/T9b68fEMC2Kfx65LfiKcYfzN94ZvIxUe+QEAAABQBIYfAAAAAEVg+AEAAABQBIYfAAAAAEVg+AEAAABQBIYfAAAAAEVg+AEAAABQBIYfAAAAAEVg+AEAAABQBIYfAAAAAEVg+AEAAABQBIYfAAAAAEVg+AEAAABQBIYfAAAAAEVg+AEAAABQBIYfAAAAAEVoTR0gZ8f/zvdSR9DzD4wPrb/yug+GM8y94Z7wbZRq2tJ4h14867TQ+sc+PjmcYeLDZ4XW9x6zN5xh+u1jwreBxrUumBdav/oPpoczvKfzO6H1//BPbwpnQGNaXnty+DZeet2U0PpnF3s4Q+vO+G0goeXfD99E9wunh9a/5qynwhlWP3JsaP2LC2vhDLGfTtPikR8AAAAARWD4AQAAAFAEhh8AAAAARWD4AQAAAFCESocfM5tiZjeb2WNmtsbMzqxyf4AOIgf0EDmgh0iNDiKFqs/29jlJ/+7ul5hZu6RxFe8P0EHkgB4iB/QQqdFBVK6y4cfMJks6W9JlkuTuXZK6qtofoIPIAT1EDughUqODSKXKp70tkLRV0nVm9pCZXWNmB5wm3MyWmNkKM1vRrX0VRkMhDttBiR5ixNFD5ID7ZKTGsRBJVDn8tEo6VdLV7n6KpF2Srhp4BXdf6u6d7t7ZJl7QEE132A5K9BAjjh4iB9wnIzWOhUiiyuFno6SN7n5v/f2b1V96oCp0EDmgh8gBPURqdBBJVDb8uPszkjaY2Un1i86TtLqq/QE6iBzQQ+SAHiI1OohUqj7b25WSbqyf0WO9pPdVvD9AB5EDeogc0EOkRgdRuUqHH3dfKamzyj2BgeggckAPkQN6iNToIFKo9EVOAQAAACAVhh8AAAAARaj6b34wTAvHPhta/53N3qQkSOXEz+0NrV/74Y5whp+77K7Q+q/eeXY4w9H/ti60vjecoGxr/mhaaP2D530+nOHcB381tP7YP74nnAGNGX/1c+HbeHFHT2h9x+74sXDBb28PrY99BsjBiZffF1q/6rrTwhmmzn8xdgOPHh3OMJrxyA8AAACAIjD8AAAAACgCww8AAACAIjD8AAAAACgCww8AAACAIjD8AAAAACgCww8AAACAIjD8AAAAACgCww8AAACAIjD8AAAAACgCww8AAACAIjD8AAAAACgCww8AAACAIjD8AAAAACgCww8AAACAIjD8AAAAACiCuXvqDIMys62Snj7M1aZJeq6COLnuX1KGee4+fYT3+DFD6GEpX38yJOqgRA9HUYaSj4VSGV9/MvTLtYelfP3JEOhgtsPPUJjZCnfvLHV/MqSXw+dOhnwypJLD506G9PunlvrzT70/GdLL4XMnQz4ZDoWnvQEAAAAoAsMPAAAAgCKM9uFnaeH7S2RILYfPnQz9csiQSg6fOxnS759a6s8/9f4SGVLL4XMnQ78cMgxqVP/NDwAAAAAM1Wh/5AcAAAAAhmRUDj9mdr6ZrTWzdWZ2VYL955rZnWa22sxWmdlHqs4wIEvNzB4ys1sS7T/FzG42s8fMbI2ZnZkiRwr08OUcdDAROnhAFnqYCD18OUfSDtYz0EN6yLHwMEbd097MrCbpcUlvkbRR0v2S3uXuqyvMMEvSLHd/0MwmSnpA0juqzDAgy29K6pQ0yd0vTLD/VyT9p7tfY2btksa5+0tV56gaPTwgBx1MgA7+WBZ6mAA9PCBH0g7WM9BDesix8DBG4yM/p0ta5+7r3b1L0k2SLq4ygLtvdvcH62/vkLRG0uwqM0iSmc2R9HZJ11S9d33/yZLOlvRlSXL3rtwKPoLooehgYnSwjh4mRQ+VvoP1DPSQHnIsHILROPzMlrRhwPsbleDOdj8zmy/pFEn3Jtj+s5I+Jqkvwd6StEDSVknX1R9ivcbMxifKUjV62I8OpkMH/xs9TIce9kvdQYke0sP0PRwVHRyNw082zGyCpK9L+qi7b6947wslbXH3B6rc9yCtkk6VdLW7nyJpl6TKn2dbulQ9pIPYj2MhPcxB4cdCiR5mofAejooOjsbhZ5OkuQPen1O/rFJm1qb+ct/o7t+oen9JiyVdZGZPqf/h3XPN7IaKM2yUtNHd9/9m42b1l74E9JAOpkYH+9HDtOhhHh2U6CE9TN/DUdHB0Tj83C9poZktqP8h1aWSllUZwMxM/c9nXOPun6ly7/3c/ePuPsfd56v/a3CHu/9KxRmekbTBzE6qX3SepMr/0DmR4ntIB5MrvoMSPcxA8T3MoYP1HPSQHnIsHILW1AGGy917zOwKSbdJqkm61t1XVRxjsaR3S3rEzFbWL/s9d7+14hw5uFLSjfWDzXpJ70ucpxL0MCt0kA7mgB7SwxzQQ3qYWvYdHHWnugYAAACARozGp70BAAAAwLAx/AAAAAAoAsMPAAAAgCIw/AAAAAAoAsMPAAAAgCIw/AAAAAAoAsMPAAAAgCIw/AAAAAAoAsMPAAAAgCIw/AAAAAAoQmvqAIfS3jrOx7ZPSRvCPbS8a0r8yzt2yt7Q+n1bOsIZant7Q+u9Fp+xd+7Y9Jy7Tw/f0DBFe+gWz9AzvhZa75Ni//8kqa879v+w45nucAb1BD+PMe2h5Xu6XlJXz+4m/B8dvvaWDh/bMrHh9X0TxoQzdB0VW//aSVvDGUyxL/+jW+OHkPYdfaH11hNbv6d7W5IeRo+F3RNixzFJ6p0Q+9qdPDHewbbg74zX7on/XNOzvS20vm1X7OsoSTt2/ijNfXLLWB9ba/xYqJb4zyPeHuty98zYz5aSNGXMntD6HZsnhDNEfzaMitwnZzv8jG2fojNO+kDSDLY39gPb0z83I5zhdRc+Flr/1NUnhjNMWbUjtL77qPgAdtftH386fCMNiPbQ2+J3+FtPCxzoJe176/Zwhl1bxofWL/rTH4Uz9L20LXYDx88NLV/+2N/G9g8Y2zJRZ07+2YbX71q8MJxhwzt7QuvveXP869dmse+nRX9zeTjD7O/Efuhoe25naP331l8XWt+ose1TdMbJ/6vh9c+eMTmcYdvi2C8DbzvnC+EMM2qxY+E5j74jnOGF214VWn/M8t3hDLff/Qdp7pNrE3Xm1EsaXm8TxoUzdM2ZGlr/o492hTP87PHfD62/61NnhTNMfCJ4nxwcRCP3yTztDQAAAEARGH4AAAAAFIHhBwAAAEARKh1+zOx8M1trZuvM7Koq9wYkOog80EPkgB4iNTqIFCobfsysJumLkt4maZGkd5nZoqr2B+ggckAPkQN6iNToIFKp8pGf0yWtc/f17t4l6SZJF1e4P0AHkQN6iBzQQ6RGB5FElcPPbEkbBry/sX7Zy8xsiZmtMLMVXT3xUzECBzlsByV6iBE3/B567BS/wCC4T0Zqwz8W9sVONQ9ImZ3wwN2Xununu3e2t8bPxQ40gh4iBwf00OKvlQUMF8dC5OCAHraMTR0HR4Aqh59Nkga+yuCc+mVAVeggckAPkQN6iNToIJKocvi5X9JCM1tgZu2SLpW0rML9ATqIHNBD5IAeIjU6iCRaq9rI3XvM7ApJt0mqSbrW3VdVtT9AB5EDeogc0EOkRgeRSmXDjyS5+62Sbq1yT2AgOogc0EPkgB4iNTqIFLI64QEAAAAAjJRKH/kZDjfJWxqfzezxp8IZenftCq0/7+efDmf47Rl3hta/d+tHwxlanvpRaH3vq04IZ0gl2sPejvi32IuLPLR+/Rk3hjN8dHNnaP19i2PrJWniTRtD62s7g6dI7euLrY+o1WRTJjW8fPux8R7+RudtofVf3nZsOMNf/13sJUBq3eEIYbYvGMJjx4OGt20x9Y5ra3h9X7uFM0xYETvT19vu/u1whnM/uDy0/rSjfxjO8C1/VWh9y+4MvhEa1WKyjjGNr2/CcfyHb42dfXPtmdeFMxx/04dC609a/Xw4Q9/6WJdrs2cFAzT+/5JHfgAAAAAUgeEHAAAAQBEYfgAAAAAUgeEHAAAAQBEYfgAAAAAUgeEHAAAAQBEYfgAAAAAUgeEHAAAAQBEYfgAAAAAUgeEHAAAAQBEYfgAAAAAUgeEHAAAAQBEYfgAAAAAUgeEHAAAAQBEYfgAAAAAUgeEHAAAAQBFaUwc4pFqLeqaMaXh5+6wZ4QibL5oVWn/9jL8IZ3jbX34sdgMnhSOotm9BaH1fq8VDpFRrPP+eYxrv8H7vPHt5aP1b1vxMOMPG78wNrd/75q5whnHPnBpaX9uyMxbAEvbYXeruaXj5mG194Qj/uDH29e/45ORwhnmPPBpa33fiseEMLU9uCq33o6eEM6RiPY33aMKm3vD+k++Lfe2feVvsOCZJ/7TmjaH1Yx8aG84w88G9ofUtXY0fS5Izk9oa/9HVW2vhCKf9z8dC6xd8c0k4w8m/tzK0fs+bXhvO0NF+XGh9X/Q+taXxx2945AcAAABAERh+AAAAABSB4QcAAABAERh+AAAAABSB4QcAAABAESobfsxsrpndaWarzWyVmX2kqr0BiQ4iD/QQOaCHSI0OIpUqT3XdI+m33P1BM5so6QEz+5a7r64wA8pGB5EDeogc0EOkRgeRRGWP/Lj7Znd/sP72DklrJM2uan+ADiIH9BA5oIdIjQ4ilSQvcmpm8yWdIunegy5fImmJJI0ZM3pfCA75O1QH6x97uYcd7fEXZgQOZcg9rE2sNBfKMpT7ZI6FGElDPha2cixEXOUnPDCzCZK+Lumj7r594Mfcfam7d7p7Z3v7+KqjoRCv1EHpwB62tY6rPiCKMJwetrfEXxUeGMxQ75Pb2rhPxsgY1rGwxn0y4iodfsysTf0Fv9Hdv1Hl3oBEB5EHeogc0EOkRgeRQpVnezNJX5a0xt0/U9W+wH50EDmgh8gBPURqdBCpVPnIz2JJ75Z0rpmtrP+7oML9ATqIHNBD5IAeIjU6iCQqO+GBu98tyaraDzgYHUQO6CFyQA+RGh1EKpWf8AAAAAAAUkhyquuhcJN6OmqN38Dco8IZ/uzya0Prf/bRy8IZzGPrX/dLj4YzLJ/1mtD6Y/9jXzhDUr2N/0/YtiDQ4bpNe2Knfd90x9xwhvbdsfVjZ+wIZ9h81tGh9fP+KZ5htOp4sTd8Gz/cPDW0vvbr8QzTv7kotP6o5ZvCGfp6ekLrW/Z2BQME7xQiWhr/Jf3k++Jfe9Viv6/dd/6PnUhs2Hqfj51tbPrK+P2h12IPlvSNaw9nSMZM3tb4j647FsXuRyRpkl4MrW/dFv+5oOWo2M8F7betCGdQR0douc2ZFdu/r6/hpTzyAwAAAKAIDD8AAAAAisDwAwAAAKAIDD8AAAAAisDwAwAAAKAIDD8AAAAAisDwAwAAAKAIDD8AAAAAisDwAwAAAKAIDD8AAAAAisDwAwAAAKAIDD8AAAAAisDwAwAAAKAIDD8AAAAAisDwAwAAAKAIDD8AAAAAitCaOsChmEute3obXv/8azvCGRa2PR9a/9L9M8IZeub3hdZ/dd53wxkWHHVyaH3r9n3hDMmYydsa/x3Bnpmx/3+StL071uUp6+IZxj3bFVr/5OsmhjPohFiGvvFjQuu9xULrQ/r65Lt2N7x83FPbwhHan54Wu4FX7whnmPprT4fWrz9xQTjDsZ9+NrS+Z8em0Hr37tD6Rllvn2rb9za8vmfDxnCG2sLjQuv3/LAJx6Fxjf9cIkmtu3rCEdqejX0/98yYFM6QTG+fbNeehpfvnhH/nf8J47eG1j++aHo4w5Ofi93G7P87O5yh9c6VsRt48qnQcu9r/GcCHvkBAAAAUASGHwAAAABFYPgBAAAAUASGHwAAAABFqHz4MbOamT1kZrdUvTcg0UHkgR4iB/QQqdFBVC3FIz8fkbQmwb7AfnQQOaCHyAE9RGp0EJWqdPgxszmS3i7pmir3Bfajg8gBPUQO6CFSo4NIoepHfj4r6WOS4i88AjSGDiIH9BA5oIdIjQ6icpUNP2Z2oaQt7v7AK1xniZmtMLMVXV27qoqGQgylg/XrvdzD7m56iOZqpIdd3viLSwKDGfZ9cm/jL7ILDKahY2Ff4y9wCuxX5SM/iyVdZGZPSbpJ0rlmdsPAK7j7UnfvdPfO9vbxFUZDIQ7bQenAHra10UM03bB72G4dVWfEkW9498m1cSky4sg2/GNhy9iqM+IIVNnw4+4fd/c57j5f0qWS7nD3X6lqf4AOIgf0EDmgh0iNDiIVXucHAAAAQBFaU2zq7ndJuivF3oBEB5EHeogc0EOkRgdRJR75AQAAAFAEhh8AAAAARUjytLch6XO17OtteHnXpHiEdz70gdD67knx09b/j9MfD61fvrfxr+F+456O1cQC/x9T85qpe8qYhte3dFk4w7HjXgyt/9GkBeEM7TtqofUTp+4MZ3CPfS17JgTPmFZL+Lsid/m+fY2vf3pTOMK8f238+0CSbFn8ePjkhbEu90zwcIaW444NrfenN4bW2974MaUhvX2y7Y2f+r924vHxDNt2hJbPuHdGOIK/O3Y83nnstHCGozbHMqgv/n2QTEuLfFzas18+vjPWo2MmxnosSS2TYv8Pn5s1L5xh8umvCa1vDfbYftTW8Foe+QEAAABQBIYfAAAAACAJ04wAABjbSURBVEVg+AEAAABQBIYfAAAAAEVg+AEAAABQBIYfAAAAAEVg+AEAAABQBIYfAAAAAEVg+AEAAABQBIYfAAAAAEVg+AEAAABQBIYfAAAAAEVg+AEAAABQBIYfAAAAAEVg+AEAAABQBIYfAAAAAEVoTR3gkFxq6elrePmrvrs7HMHuag+t7zjBwhnu9xND69/dfVI4w/y794TWt+zeG86QivW5Wnf1NLx+6qr4t9i/znxd7AY6G8+/3wuvj/2epHPalnCGlf8Z+15o2Rc8JvR5bH1ES4ts4oTG108cH47w4qsD+0vaMS9+PPzJCx4Orb/z7uD3kiR5rActM6fH9v9Rmrttb6upd+aUhte/dPLEcIbdx8wMrb/8/d8MZ7jrxdh96tatk8MZfFxHaH33pNjPNmm51Nf4z4ZTH4v/PHL/o8eH1p+y6AfhDF19sePAnqPjj32MeSnWw7E9se8F31JreC2P/AAAAAAoAsMPAAAAgCIw/AAAAAAoAsMPAAAAgCJUOvyY2RQzu9nMHjOzNWZ2ZpX7A3QQOaCHyAE9RGp0EClUfdqYz0n6d3e/xMzaJY2reH+ADiIH9BA5oIdIjQ6icpUNP2Y2WdLZki6TJHfvktRV1f4AHUQO6CFyQA+RGh1EKlU+7W2BpK2SrjOzh8zsGjOLv/gEMHR0EDmgh8gBPURqdBBJVDn8tEo6VdLV7n6KpF2Srhp4BTNbYmYrzGxFd8+uCqOhEIftoHRQD7vpIZpu2D3s6ou90DAwiGHeJ8dfOBw4yPCPhb0cCxFX5fCzUdJGd7+3/v7N6i/9y9x9qbt3untnWyvDP5rusB2UDuphGz1E0w27h+0tYysNiCIM8z6ZP8VA0w3/WFjjWIi4yoYfd39G0gYzO6l+0XmSVle1P0AHkQN6iBzQQ6RGB5FK1Wd7u1LSjfUzeqyX9L6K9wfoIHJAD5EDeojU6CAqV+nw4+4rJXVWuScwEB1EDughckAPkRodRAqVvsgpAAAAAKTC8AMAAACgCFX/zc+Qmbusq6fh9W0794Yz9EyNnemr1uXhDNHxdMraeARvtdD67mMmx0M8Gb+JRlivq7at8S5NWh/vwL7JsR7O+8X4F6+jtTu0/r6VC8MZZj7ShO+n0aqvT747cIrXY44OR9g7LXYc+NVfuC2cYd3uGaH1YzfHf9/nY9tD623PvnCG0ahtd/z7d8/02G3csuX14Qxrl88PrZ89tvGfa/bbPS92n1rb1xfOkExvn7Sj8ZegaNsS/7H3mO/Gjqeb500KZ+jprYXW93aEI6i2tze0vmV77LTl1tv48YBHfgAAAAAUgeEHAAAAQBEYfgAAAAAUgeEHAAAAQBEYfgAAAAAUgeEHAAAAQBEYfgAAAAAUgeEHAAAAQBEYfgAAAAAUgeEHAAAAQBEYfgAAAAAUgeEHAAAAQBEYfgAAAAAUgeEHAAAAQBEYfgAAAAAUgeEHAAAAQBHM3VNnGJSZbZX09GGuNk3ScxXEyXX/kjLMc/fpI7zHjxlCD0v5+pMhUQclejiKMpR8LJTK+PqToV+uPSzl60+GQAezHX6GwsxWuHtnqfuTIb0cPncy5JMhlRw+dzKk3z+11J9/6v3JkF4OnzsZ8slwKDztDQAAAEARGH4AAAAAFGG0Dz9LC99fIkNqOXzuZOiXQ4ZUcvjcyZB+/9RSf/6p95fIkFoOnzsZ+uWQYVCj+m9+AAAAAGCoRvsjPwAAAAAwJAw/AAAAAIowKocfMzvfzNaa2TozuyrB/nPN7E4zW21mq8zsI1VnGJClZmYPmdktifafYmY3m9ljZrbGzM5MkSMFevhyDjqYCB08IAs9TIQevpwjaQfrGeghPeRYeBij7m9+zKwm6XFJb5G0UdL9kt7l7qsrzDBL0ix3f9DMJkp6QNI7qswwIMtvSuqUNMndL0yw/1ck/ae7X2Nm7ZLGuftLVeeoGj08IAcdTIAO/lgWepgAPTwgR9IO1jPQQ3rIsfAwRuMjP6dLWufu6929S9JNki6uMoC7b3b3B+tv75C0RtLsKjNIkpnNkfR2SddUvXd9/8mSzpb0ZUly967cCj6C6KHoYGJ0sI4eJkUPlb6D9Qz0kB5yLByC0Tj8zJa0YcD7G5XgznY/M5sv6RRJ9ybY/rOSPiapL8HekrRA0lZJ19UfYr3GzMYnylI1etiPDqZDB/8bPUyHHvZL3UGJHtLD9D0cFR0cjcNPNsxsgqSvS/qou2+veO8LJW1x9weq3PcgrZJOlXS1u58iaZekyp9nW7pUPaSD2I9jIT3MQeHHQokeZqHwHo6KDo7G4WeTpLkD3p9Tv6xSZtam/nLf6O7fqHp/SYslXWRmT6n/4d1zzeyGijNslLTR3ff/ZuNm9Ze+BPSQDqZGB/vRw7ToYR4dlOghPUzfw1HRwdE4/NwvaaGZLaj/IdWlkpZVGcDMTP3PZ1zj7p+pcu/93P3j7j7H3eer/2twh7v/SsUZnpG0wcxOql90nqTK/9A5keJ7SAeTK76DEj3MQPE9zKGD9Rz0kB5yLByC1tQBhsvde8zsCkm3SapJutbdV1UcY7Gkd0t6xMxW1i/7PXe/teIcObhS0o31g816Se9LnKcS9DArdJAO5oAe0sMc0EN6mFr2HRx1p7oGAAAAgEaMxqe9AQAAAMCwMfwAAAAAKALDDwAAAIAiMPwAAAAAKALDDwAAAIAiMPwAAAAAKEJo+DGzqWb2LTN7ov7fow5xvV4zW1n/V+mLTuHIRw+RA3qI1OggckAPkbvQ6/yY2V9IesHdP21mV0k6yt1/d5Dr7XT3CYGcwCHRQ+SAHiI1Oogc0EPkLjr8rJV0jrtvNrNZku5y95MGuR4Fx4ihh8gBPURqdBA5oIfIXfRvfma6++b6289ImnmI63WY2QozW25m7wjuCRyMHiIH9BCp0UHkgB4ia62Hu4KZfVvSMYN86PcHvuPubmaHehhpnrtvMrPjJN1hZo+4+5OD7LVE0hJJGjvOTpt//GHjHfHGGeekkKQHvr+vW9Ljg3xoRHs4fpyddvIJ7cH0o98Tj01JHSG5PT3b1N2393YlOB7WOlpPmzBv0KfNF6VvbU/qCMnt1Ety+apBPjSyHVTraeNbOQ54T2/qCFnYoRe5T05o7dPTUkdIbu/uF9XdtcsaWVvJ094OWnO9pFvc/eZXut6i17f7/7vlUL8sKMfr2ztSR8hCbda6B9y9c7CPjWQPO9/Q4ffdNrfR2EeMty++OHWE5O7ZeIO27XvmkAfakezhlJNn+Nl/+wuNxD6i7HnTs6kjJHev367t/sKgPRzJDk5um+5nTvm5RmMfMXqffyF1hCx822/mPjmhN31wSeoIya38zue046WNDQ0/0YcVlkl6b/3t90r65sFXMLOjzGxM/e1pkhZLWh3cFxiIHiIH9BCp0UHkgB4ia9Hh59OS3mJmT0h6c/19mVmnmV1Tv86rJa0ws4cl3Snp0+5OwdFM9BA5oIdIjQ4iB/QQWQv9UY27Py/pvEEuXyHpA/W375H0usg+wCuhh8gBPURqdBA5oIfIHX9NDwAAAKAIDD8AAAAAisDwAwAAAKAIDD8AAAAAisDwAwAAAKAIDD8AAAAAisDwAwAAAKAIDD8AAAAAisDwAwAAAKAIDD8AAAAAisDwAwAAAKAIDD8AAAAAisDwAwAAAKAIDD8AAAAAisDwAwAAAKAIDD8AAAAAisDwAwAAAKAIDD8AAAAAisDwAwAAAKAIDD8AAAAAisDwAwAAAKAIDD8AAAAAisDwAwAAAKAIDD8AAAAAitCU4cfMzjeztWa2zsyuGuTjY8zs7+sfv9fM5jdjX2Ageogc0EOkRgeRA3qIXIWHHzOrSfqipLdJWiTpXWa26KCrvV/Si+5+gqS/kvTn0X2BgeghckAPkRodRA7oIXLWjEd+Tpe0zt3Xu3uXpJskXXzQdS6W9JX62zdLOs/MrAl7A/vRQ+SAHiI1Oogc0ENkqxnDz2xJGwa8v7F+2aDXcfceSdskHX3wDZnZEjNbYWYrXnqhrwnRUJAR6eHW53tHKC6OUCPSw66X9oxQXByBRqaDfXtHKC6OUNwnI1tZnfDA3Ze6e6e7d06ZmlU0FGRgD6cfXUsdB4Ua2MP2KWNTx0GBDuhgS0fqOCgU98lotmZMGJskzR3w/pz6ZYNex8xaJU2W9HwT9gb2o4fIAT1EanQQOaCHyFYzhp/7JS00swVm1i7pUknLDrrOMknvrb99iaQ73N2bsDewHz1EDughUqODyAE9RLZaozfg7j1mdoWk2yTVJF3r7qvM7JOSVrj7MklflvR3ZrZO0gvq/yYAmoYeIgf0EKnRQeSAHiJn4eFHktz9Vkm3HnTZJwa8vVfSO5uxF3Ao9BA5oIdIjQ4iB/QQueKsAgAAAACKwPADAAAAoAgMPwAAAACKwPADAAAAoAgMPwAAAACKwPADAAAAoAgMPwAAAACKwPADAAAAoAgMPwAAAACKwPADAAAAoAgMPwAAAACKwPADAAAAoAgMPwAAAACKwPADAAAAoAgMPwAAAACKwPADAAAAoAgMPwAAAACKwPADAAAAoAgMPwAAAACKwPADAAAAoAgMPwAAAACKwPADAAAAoAgMPwAAAACKwPADAAAAoAhNGX7M7HwzW2tm68zsqkE+fpmZbTWzlfV/H2jGvsBA9BCp0UHkgB4iB/QQuWqN3oCZ1SR9UdJbJG2UdL+ZLXP31Qdd9e/d/YrofsBg6CFSo4PIAT1EDughctaMR35Ol7TO3de7e5ekmyRd3ITbBYaDHiI1Oogc0EPkgB4iW+FHfiTNlrRhwPsbJf3EINf7eTM7W9Ljkn7D3TccfAUzWyJpiSTVpk7Rxf/+4SbEG91O/NB9qSNkYt3hrjAiPRzTMUXnXsYj8W0/WJE6QnL999+vqGkdlA7sYfuMSXp294RhZz7SfO9Ht6WOkNzpb919uKuMyLHw2NmtunXFHQ1lPpIcf8f7UkfIwy/ffLhrjEgP28cdpbN+40MNRT6STPyX5akjJGd+2GPhIVV1woN/kTTf3V8v6VuSvjLYldx9qbt3untnbcL4iqKhIMPuYVs7PURTDamD0oE9bJ08rrKAKMKwj4XTj65VGhBFGP598hjukxHXjOFnk6S5A96fU7/sZe7+vLvvq797jaTTmrAvMBA9RGp0EDmgh8gBPUS2mjH83C9poZktMLN2SZdKWjbwCmY2a8C7F0la04R9gYHoIVKjg8gBPUQO6CGyFf6bH3fvMbMrJN0mqSbpWndfZWaflLTC3ZdJ+rCZXSSpR9ILki6L7gsMRA+RGh1EDughckAPkbNmnPBA7n6rpFsPuuwTA97+uKSPN2Mv4FDoIVKjg8gBPUQO6CFyVdUJDwAAAAAgKYYfAAAAAEVg+AEAAABQBIYfAAAAAEVg+AEAAABQBIYfAAAAAEVg+AEAAABQBIYfAAAAAEVg+AEAAABQBIYfAAAAAEVg+AEAAABQBIYfAAAAAEVg+AEAAABQBIYfAAAAAEVg+AEAAABQBIYfAAAAAEVg+AEAAABQBIYfAAAAAEVg+AEAAABQBIYfAAAAAEVg+AEAAABQBIYfAAAAAEVg+AEAAABQBIYfAAAAAEVoyvBjZtea2RYze/QQHzcz+7yZrTOz75vZqc3YF9iPDiIH9BA5oIdIjQ4iZ8165Od6See/wsffJmlh/d8SSVc3aV9gv+tFB5He9aKHSO960UOkdb3oIDLVlOHH3b8r6YVXuMrFkr7q/ZZLmmJms5qxNyDRQeSBHiIH9BCp0UHkrKq/+ZktacOA9zfWLzuAmS0xsxVmtqJ3566KoqEQQ+qgdGAPu7voIZqqoR72bNtdSTgUY9j3yVuf760sHIrQ2H3yPu6TEZfVCQ/cfam7d7p7Z23C+NRxUKiBPWxrp4dIY2APWyePSx0HBRrYwelH11LHQaEOuE8ew30y4qoafjZJmjvg/Tn1y4Cq0EHkgB4iB/QQqdFBJFPV8LNM0nvqZ/c4Q9I2d99c0d6ARAeRB3qIHNBDpEYHkUxrM27EzL4m6RxJ08xso6Q/ktQmSe7+JUm3SrpA0jpJuyW9rxn7AvvRQeSAHiIH9BCp0UHkrCnDj7u/6zAfd0m/3oy9gMHQQeSAHiIH9BCp0UHkLKsTHgAAAADASGH4AQAAAFAEhh8AAAAARWD4AQAAAFAEhh8AAAAARWD4AQAAAFAEhh8AAAAARWD4AQAAAFAEhh8AAAAARWD4AQAAAFAEhh8AAAAARWD4AQAAAFAEhh8AAAAARWD4AQAAAFAEhh8AAAAARWD4AQAAAFAEhh8AAAAARWD4AQAAAFAEhh8AAAAARWD4AQAAAFAEhh8AAAAARWD4AQAAAFAEhh8AAAAARWjK8GNm15rZFjN79BAfP8fMtpnZyvq/TzRjX2A/Oogc0EOkRgeRA3qInLU26Xaul/QFSV99hev8p7tf2KT9gINdLzqI9K4XPURa14sOIr3rRQ+RqaY88uPu35X0QjNuC2gEHUQO6CFSo4PIAT1Ezqr8m58zzexhM/s3M3tNhfsC+9FB5IAeIjU6iBzQQyRh7t6cGzKbL+kWd3/tIB+bJKnP3Xea2QWSPufuCwe53hJJS+rvvlbSoM8VrdA0Sc+RIYsMJ7n7xFe6QjM6WL8uPcwvQ+r9pSF0UKKHR/D+uWTgWEiGHDLQw7IzpN5fGuJ98mAqGX4Gue5Tkjrd/ZBfODNb4e6dTQnXIDKMrgzN7uBQ9x1pZEi//3Ay0MMjc//RlIEOkiGHDPTwyM2Qev9ohkqe9mZmx5iZ1d8+vb7v81XsDUh0EHmgh0iNDiIH9BApNeVsb2b2NUnnSJpmZhsl/ZGkNkly9y9JukTSr5lZj6Q9ki71Zj3kBIgOIg/0EKnRQeSAHiJnTRl+3P1dh/n4F9R/ysPhWNp4oqYhQ7/sM4xQBw+7b0XIkH5/aQgZ6OERvb80CjLQwRFHhn70MK3UGVLvLwUyNO1vfgAAAAAgZ1We6hoAAAAAkslm+DGzqWb2LTN7ov7fow5xvV4zW1n/t6xJe59vZmvNbJ2ZXTXIx8eY2d/XP35v/QwmTTWEDJeZ2dYBn/sHmrz/tWa2xcwGPYWk9ft8Pd/3zezUZu4/xAznmNm2AV+DT4xAhmJ7mLqD9T2S9jCHDtb3SdLD1B0cYgaOhRwL6SE9PPh6R1wPU3ewvseReZ/s7ln8k/QXkq6qv32VpD8/xPV2NnnfmqQnJR0nqV3Sw5IWHXSdyyV9qf72pZL+PkGGyyR9YQS//mdLOlXSo4f4+AWS/k2SSTpD0r0JMpyj/tNm0sMm9zCHDubQwxw6mKqHqTuYSw9TdzCXHpZ6LKSH9DCHHubQwRx6OFIdzOaRH0kXS/pK/e2vSHpHRfueLmmdu6939y5JN9WzHCrbzZLOM+s/RWOFGUaUu39X0guvcJWLJX3V+y2XNMXMZlWcoQql9jB5B6X0Pcykg1KaHqbu4FAzjKjUHRxihiqUeiwcaoYRRQ9fVmoPk3dQSt/DkepgTsPPTHffXH/7GUkzD3G9DjNbYWbLzawZ3wSzJW0Y8P7G+mWDXsfdeyRtk3R0E/YeTgZJ+vn6w4o3m9ncJu4/FEPNONLONLOHzezfzOw1I3D7pfZwNHRQyqOHI91BKU0PU3dwqBkkjoUSx0J6SA8HOtJ6OBo6KOXRw2F3sCmnuh4qM/u2pGMG+dDvD3zH3d3MDnUaunnuvsnMjpN0h5k94u5PNjtrhv5F0tfcfZ+ZfVD9v204N3Gmqj2o/v//O83sAkn/LGnhcG+EHjaMDjapgxI9DKCHHAtzQA/pYWp0sMEOVjr8uPubD/UxM3vWzGa5++b6Q2ZbDnEbm+r/XW9md0k6Rf3Pi2zUJkkDp+U59csGu85GM2uVNFnNfSXiw2Zw94H7XaP+58FWaShfpxHl7tsHvH2rmf2NmU1z9+eGeTv0sIH9M+iglLiHzepgfX1uPUzdwSFlyKCHHAsPvI0j7Vg4pAz0kB6K+2RplN4n5/S0t2WS3lt/+72SvnnwFczsKDMbU397mqTFklYH971f0kIzW2Bm7er/o7WDzxQyMNslku5w92a+QNJhMxz0HMqLJK1p4v5DsUzSe6zfGZK2DXgouhJmdoxZ//Npzex09fe3mXd4Urk9HA0dlBL3sKIOSml6mLqDQ8qQQQ85Fv53jiPxWDikDPSQHor7ZGm03if7CJ4lYjj/1P88ydslPSHp25Km1i/vlHRN/e2zJD2i/rNePCLp/U3a+wJJj6v/twS/X7/sk5Iuqr/dIekfJa2TdJ+k40bg8z9chj+TtKr+ud8p6eQm7/81SZsldav/OZvvl/QhSR+qf9wkfbGe7xFJnSPwNThchisGfA2WSzqLHh45Hcyhhzl0MGUPU3cwhx6m7mAuPUzVQXpID+lhHh3MoYcj1UGrLwYAAACAI1pOT3sDAAAAgBHD8AMAAACgCAw/AAAAAIrA8AMAAACgCAw/AAAAAIrA8AMAAACgCAw/AAAAAIrA8AMAAACgCP8f64KgLil/vBoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1008x1008 with 15 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# muestra los resultados de las cuatro capas de convolucion\n",
    "plt.figure(figsize=(14,14))\n",
    "offset = 100\n",
    "for i in range(5):\n",
    "    plt.subplot(5,5,i+1) #imagenes originales\n",
    "    plt.imshow((inputs[i+offset][0].detach().numpy()))\n",
    "    plt.title(Y[i+offset])\n",
    "    \n",
    "    j=0 # las imagenes reconstruidas por el autoencoder\n",
    "    plt.subplot(5,5,(i+1)+5*(j+1))\n",
    "    plt.imshow(x_transform[i+offset][0].detach().numpy())\n",
    "    \n",
    "    j=1 # una de las capas de la representacion latente\n",
    "    plt.subplot(5,5,(i+1)+5*(j+1))\n",
    "    plt.imshow(latent_space[i+offset][0].detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_p=0\n",
    "for m in model.parameters():\n",
    "    n_p+=m.flatten().size()[0]\n",
    "\n",
    "N_Cs.append(n_p)\n",
    "losses.append(loss.item)\n",
    "N_Ls.append(latent_space.size()[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segunda corrida introduciendo un stride al inicio de ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define el autoencoder\n",
    "class Autoencoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder,self).__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3,stride=1),\n",
    "            torch.nn.Conv2d(32,16,kernel_size=3),\n",
    "            torch.nn.Conv2d(16,10,kernel_size= 3))\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(10,8,kernel_size=3),\n",
    "            torch.nn.ConvTranspose2d(8,16,kernel_size=3),\n",
    "            torch.nn.ConvTranspose2d(16,1,kernel_size=3))\n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializa modelo, loss y optimizador\n",
    "num_epochs = 100\n",
    "model = Autoencoder()\n",
    "distance = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1E-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:2.2713\n",
      "epoch [26/100], loss:0.8539\n",
      "epoch [51/100], loss:0.6414\n",
      "epoch [76/100], loss:0.5408\n",
      "epoch [100/100], loss:0.4822\n"
     ]
    }
   ],
   "source": [
    "# entrenamiento\n",
    "loss_list = [] \n",
    "for epoch in range(num_epochs):\n",
    "    output = model(inputs)\n",
    "    loss = distance(output, inputs)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_list.append(loss.item())\n",
    "    if epoch==0 or epoch==25 or epoch==50 or epoch==75 or epoch==99:\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1797, 10, 2, 2])\n",
      "8435\n"
     ]
    }
   ],
   "source": [
    "x_transform = model(inputs)\n",
    "latent_space = model.encoder(inputs)\n",
    "print(latent_space.size())\n",
    "n_p=0\n",
    "for m in model.parameters():\n",
    "    n_p+=m.flatten().size()[0]\n",
    "print(n_p)\n",
    "N_Cs.append(n_p)\n",
    "losses.append(loss.item)\n",
    "N_Ls.append(latent_space.size()[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tercera: Aumentando la profundidad de la red ENCODER en una capa más"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define el autoencoder\n",
    "class Autoencoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder,self).__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 50, kernel_size=2),\n",
    "            torch.nn.Conv2d(50,32,kernel_size=2),\n",
    "            torch.nn.Conv2d(32,16,kernel_size= 3),\n",
    "            torch.nn.Conv2d(16,10,kernel_size= 3))\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(10,8,kernel_size=3),\n",
    "            torch.nn.ConvTranspose2d(8,16,kernel_size=3),\n",
    "            torch.nn.ConvTranspose2d(16,1,kernel_size=3))\n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializa modelo, loss y optimizador\n",
    "num_epochs = 100\n",
    "model = Autoencoder()\n",
    "distance = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1E-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:2.1089\n",
      "epoch [26/100], loss:0.8362\n",
      "epoch [51/100], loss:0.5765\n",
      "epoch [76/100], loss:0.4453\n",
      "epoch [100/100], loss:0.3856\n"
     ]
    }
   ],
   "source": [
    "# entrenamiento\n",
    "loss_list = [] \n",
    "for epoch in range(num_epochs):\n",
    "    output = model(inputs)\n",
    "    loss = distance(output, inputs)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_list.append(loss.item())\n",
    "    if epoch==0 or epoch==25 or epoch==50 or epoch==75 or epoch==99:\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1797, 10, 2, 2])\n",
      "14797\n"
     ]
    }
   ],
   "source": [
    "x_transform = model(inputs)\n",
    "latent_space = model.encoder(inputs)\n",
    "print(latent_space.size())\n",
    "n_p=0\n",
    "for m in model.parameters():\n",
    "    n_p+=m.flatten().size()[0]\n",
    "print(n_p)\n",
    "N_Cs.append(n_p)\n",
    "losses.append(loss.item)\n",
    "N_Ls.append(latent_space.size()[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cuarta: Aumentar el Kernel modificando lo que sea necesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define el autoencoder\n",
    "class Autoencoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder,self).__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 8, kernel_size=5),\n",
    "            torch.nn.Conv2d(8,10,kernel_size=3))\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(10,8,kernel_size=3),\n",
    "            torch.nn.ConvTranspose2d(8,16,kernel_size=3),\n",
    "            torch.nn.ConvTranspose2d(16,1,kernel_size=3))\n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializa modelo, loss y optimizador\n",
    "num_epochs = 100\n",
    "model = Autoencoder()\n",
    "distance = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1E-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:1.9564\n",
      "epoch [26/100], loss:0.7123\n",
      "epoch [51/100], loss:0.5125\n",
      "epoch [76/100], loss:0.4207\n",
      "epoch [100/100], loss:0.3666\n"
     ]
    }
   ],
   "source": [
    "# entrenamiento\n",
    "loss_list = [] \n",
    "for epoch in range(num_epochs):\n",
    "    output = model(inputs)\n",
    "    loss = distance(output, inputs)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_list.append(loss.item())\n",
    "    if epoch==0 or epoch==25 or epoch==50 or epoch==75 or epoch==99:\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1797, 10, 2, 2])\n",
      "2979\n"
     ]
    }
   ],
   "source": [
    "x_transform = model(inputs)\n",
    "latent_space = model.encoder(inputs)\n",
    "print(latent_space.size())\n",
    "n_p=0\n",
    "for m in model.parameters():\n",
    "    n_p+=m.flatten().size()[0]\n",
    "print(n_p)\n",
    "N_Cs.append(n_p)\n",
    "losses.append(loss.item)\n",
    "N_Ls.append(latent_space.size()[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quinta: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define el autoencoder\n",
    "class Autoencoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder,self).__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3),\n",
    "            torch.nn.Conv2d(32,16,kernel_size=3),\n",
    "            torch.nn.Conv2d(16,10,kernel_size= 3))\n",
    "            \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(10,8,kernel_size=5),\n",
    "            torch.nn.ConvTranspose2d(8,1,kernel_size=3))\n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializa modelo, loss y optimizador\n",
    "num_epochs = 100\n",
    "model = Autoencoder()\n",
    "distance = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1E-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:2.4369\n",
      "epoch [26/100], loss:0.5600\n",
      "epoch [51/100], loss:0.3991\n",
      "epoch [76/100], loss:0.3374\n",
      "epoch [100/100], loss:0.3018\n"
     ]
    }
   ],
   "source": [
    "# entrenamiento\n",
    "loss_list = [] \n",
    "for epoch in range(num_epochs):\n",
    "    output = model(inputs)\n",
    "    loss = distance(output, inputs)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_list.append(loss.item())\n",
    "    if epoch==0 or epoch==25 or epoch==50 or epoch==75 or epoch==99:\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1797, 10, 2, 2])\n",
      "8475\n"
     ]
    }
   ],
   "source": [
    "x_transform = model(inputs)\n",
    "latent_space = model.encoder(inputs)\n",
    "print(latent_space.size())\n",
    "n_p=0\n",
    "for m in model.parameters():\n",
    "    n_p+=m.flatten().size()[0]\n",
    "print(n_p)\n",
    "N_Cs.append(n_p)\n",
    "losses.append(loss.item)\n",
    "N_Ls.append(latent_space.size()[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sexta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define el autoencoder\n",
    "class Autoencoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder,self).__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=1),\n",
    "            torch.nn.Conv2d(32,16,kernel_size=1),\n",
    "            torch.nn.Conv2d(16,10,kernel_size= 1))\n",
    "            \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(10,8,kernel_size=1),\n",
    "            torch.nn.ConvTranspose2d(8,1,kernel_size=1))\n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializa modelo, loss y optimizador\n",
    "num_epochs = 100\n",
    "model = Autoencoder()\n",
    "distance = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1E-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:2.1481\n",
      "epoch [26/100], loss:0.0047\n",
      "epoch [51/100], loss:0.0009\n",
      "epoch [76/100], loss:0.0003\n",
      "epoch [100/100], loss:0.0000\n"
     ]
    }
   ],
   "source": [
    "# entrenamiento\n",
    "loss_list = [] \n",
    "for epoch in range(num_epochs):\n",
    "    output = model(inputs)\n",
    "    loss = distance(output, inputs)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_list.append(loss.item())\n",
    "    if epoch==0 or epoch==25 or epoch==50 or epoch==75 or epoch==99:\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1797, 10, 8, 8])\n",
      "859\n"
     ]
    }
   ],
   "source": [
    "x_transform = model(inputs)\n",
    "latent_space = model.encoder(inputs)\n",
    "print(latent_space.size())\n",
    "n_p=0\n",
    "for m in model.parameters():\n",
    "    n_p+=m.flatten().size()[0]\n",
    "print(n_p)\n",
    "N_Cs.append(n_p)\n",
    "losses.append(loss.item)\n",
    "N_Ls.append(latent_space.size()[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Séptima:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define el autoencoder\n",
    "class Autoencoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder,self).__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=2),\n",
    "            torch.nn.Conv2d(32,16,kernel_size=2),\n",
    "            torch.nn.Conv2d(16,10,kernel_size= 2))\n",
    "            \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(10,8,kernel_size=3),\n",
    "            torch.nn.ConvTranspose2d(8,1,kernel_size=2))\n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializa modelo, loss y optimizador\n",
    "num_epochs = 100\n",
    "model = Autoencoder()\n",
    "distance = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1E-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:1.7377\n",
      "epoch [26/100], loss:0.4639\n",
      "epoch [51/100], loss:0.3329\n",
      "epoch [76/100], loss:0.2793\n",
      "epoch [100/100], loss:0.2526\n"
     ]
    }
   ],
   "source": [
    "# entrenamiento\n",
    "loss_list = [] \n",
    "for epoch in range(num_epochs):\n",
    "    output = model(inputs)\n",
    "    loss = distance(output, inputs)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_list.append(loss.item())\n",
    "    if epoch==0 or epoch==25 or epoch==50 or epoch==75 or epoch==99:\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1797, 10, 5, 5])\n",
      "3635\n"
     ]
    }
   ],
   "source": [
    "x_transform = model(inputs)\n",
    "latent_space = model.encoder(inputs)\n",
    "print(latent_space.size())\n",
    "n_p=0\n",
    "for m in model.parameters():\n",
    "    n_p+=m.flatten().size()[0]\n",
    "print(n_p)\n",
    "N_Cs.append(n_p)\n",
    "losses.append(loss.item)\n",
    "N_Ls.append(latent_space.size()[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Octava:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define el autoencoder\n",
    "class Autoencoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder,self).__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=2),\n",
    "            torch.nn.Conv2d(32,10,kernel_size=2))\n",
    "            \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(10,8,kernel_size=3),\n",
    "            torch.nn.ConvTranspose2d(8,1,kernel_size=2))\n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializa modelo, loss y optimizador\n",
    "num_epochs = 100\n",
    "model = Autoencoder()\n",
    "distance = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1E-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:3.5063\n",
      "epoch [26/100], loss:0.5215\n",
      "epoch [51/100], loss:0.3798\n",
      "epoch [76/100], loss:0.3140\n",
      "epoch [100/100], loss:0.2790\n"
     ]
    }
   ],
   "source": [
    "# entrenamiento\n",
    "loss_list = [] \n",
    "for epoch in range(num_epochs):\n",
    "    output = model(inputs)\n",
    "    loss = distance(output, inputs)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_list.append(loss.item())\n",
    "    if epoch==0 or epoch==25 or epoch==50 or epoch==75 or epoch==99:\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1797, 10, 5, 5])\n",
      "2371\n"
     ]
    }
   ],
   "source": [
    "x_transform = model(inputs)\n",
    "latent_space = model.encoder(inputs)\n",
    "print(latent_space.size())\n",
    "n_p=0\n",
    "for m in model.parameters():\n",
    "    n_p+=m.flatten().size()[0]\n",
    "print(n_p)\n",
    "N_Cs.append(n_p)\n",
    "losses.append(loss.item)\n",
    "N_Ls.append(latent_space.size()[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Novena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define el autoencoder\n",
    "class Autoencoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder,self).__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=2),\n",
    "            torch.nn.Conv2d(32,16,kernel_size=2),\n",
    "            torch.nn.Conv2d(16,10,kernel_size= 4))\n",
    "            \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(10,8,kernel_size=4),\n",
    "            torch.nn.ConvTranspose2d(8,1,kernel_size=3))\n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializa modelo, loss y optimizador\n",
    "num_epochs = 100\n",
    "model = Autoencoder()\n",
    "distance = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1E-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:2.7098\n",
      "epoch [26/100], loss:0.5417\n",
      "epoch [51/100], loss:0.3620\n",
      "epoch [76/100], loss:0.2882\n",
      "epoch [100/100], loss:0.2417\n"
     ]
    }
   ],
   "source": [
    "# entrenamiento\n",
    "loss_list = [] \n",
    "for epoch in range(num_epochs):\n",
    "    output = model(inputs)\n",
    "    loss = distance(output, inputs)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_list.append(loss.item())\n",
    "    if epoch==0 or epoch==25 or epoch==50 or epoch==75 or epoch==99:\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1797, 10, 3, 3])\n",
      "6155\n"
     ]
    }
   ],
   "source": [
    "x_transform = model(inputs)\n",
    "latent_space = model.encoder(inputs)\n",
    "print(latent_space.size())\n",
    "n_p=0\n",
    "for m in model.parameters():\n",
    "    n_p+=m.flatten().size()[0]\n",
    "print(n_p)\n",
    "N_Cs.append(n_p)\n",
    "losses.append(loss.item)\n",
    "N_Ls.append(latent_space.size()[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Décima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define el autoencoder\n",
    "class Autoencoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder,self).__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 16, kernel_size=4),\n",
    "            torch.nn.Conv2d(16,10,kernel_size=3))\n",
    "            \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(10,8,kernel_size=4),\n",
    "            torch.nn.ConvTranspose2d(8,1,kernel_size=3))\n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializa modelo, loss y optimizador\n",
    "num_epochs = 100\n",
    "model = Autoencoder()\n",
    "distance = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1E-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:2.7649\n",
      "epoch [26/100], loss:0.5862\n",
      "epoch [51/100], loss:0.3918\n",
      "epoch [76/100], loss:0.3152\n",
      "epoch [100/100], loss:0.2681\n"
     ]
    }
   ],
   "source": [
    "# entrenamiento\n",
    "loss_list = [] \n",
    "for epoch in range(num_epochs):\n",
    "    output = model(inputs)\n",
    "    loss = distance(output, inputs)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_list.append(loss.item())\n",
    "    if epoch==0 or epoch==25 or epoch==50 or epoch==75 or epoch==99:\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1797, 10, 3, 3])\n",
      "3083\n"
     ]
    }
   ],
   "source": [
    "x_transform = model(inputs)\n",
    "latent_space = model.encoder(inputs)\n",
    "print(latent_space.size())\n",
    "n_p=0\n",
    "for m in model.parameters():\n",
    "    n_p+=m.flatten().size()[0]\n",
    "print(n_p)\n",
    "N_Cs.append(n_p)\n",
    "losses.append(loss.item)\n",
    "N_Ls.append(latent_space.size()[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Las gráficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>,\n",
       " <function Tensor.item>]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'N_Cs vs N_Ls')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.scatter(N_Cs,N_Ls)\n",
    "plt.title(\"N_Cs vs N_Ls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
